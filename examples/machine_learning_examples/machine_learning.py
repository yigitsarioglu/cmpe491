# -*- coding: utf-8 -*-
"""machine_learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qxzJCpP8Sw7sdjnwXB4HjId8_PrbuyXe
"""

# DATASET DOSYASINI GOOGLE DRİVE /tmp klasörüne unzip edilmesi
import shutil
from google.colab import drive

drive.mount("/content/gdrive")
# Change the code below if the path to the dataset is different for you.
shutil.unpack_archive("/content/gdrive/MyDrive/linearcsv.zip", "/tmp/")
shutil.unpack_archive("/content/gdrive/MyDrive/2016dolaralis.zip", "/tmp/")
shutil.unpack_archive("/content/gdrive/MyDrive/breast_cancer.zip", "/tmp/")
shutil.unpack_archive("/content/gdrive/MyDrive/tensors.zip", "/tmp/")

# Filepath kontrol edilmesi
import os

file_path = r"/tmp/linear.csv"
if os.path.exists(file_path):
    print("Dosya bulundu.")
else:
    print("Dosya bulunamadı.")

# Daire Metrekare ve Fiyat Tahmini
# Lineer Regressyon örneği
import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression as lr
import matplotlib.pyplot as plt

data = pd.read_csv(file_path)

x= data ["metrekare"]
y = data ["fiyat"]

x = x.values.reshape(99,1)
y = y.values.reshape (99,1)

lineerregresyon = lr()

lineerregresyon.fit(x,y)

lineerregresyon.predict(x)

m = lineerregresyon.coef_
b= lineerregresyon.intercept_

print("Eğim : " , m )
print(" Y eksenini kestiği yer : " , b )

a = np.arange (150)

plt.scatter(x,y)
# plt.scatter(a, m*a +b)
plt.show()

# Daire Metrekare ve Fiyat Tahmini
# İnput ile sorup ne kadar olduğu bulunur


import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt

# Veriyi okuma
data = pd.read_csv(file_path)

# Metrekare ve fiyat değerlerini alalım
X = data["metrekare"].values.reshape(-1, 1)  # X'i 2 boyutlu hale getiriyoruz
y = data["fiyat"].values

# Doğrusal regresyon modeli oluşturma
model = LinearRegression()
model.fit(X, y)

# Tahmin edilen fiyatlar
y_pred = model.predict(X)



# Yeni bir değer için tahmin
z = int(input("Kaç metrekare? "))
tahmin = model.predict([[z]])
print(f"Tahmini fiyat: {tahmin[0]}")

# Modelin parametreleri
print(f"y = {model.coef_[0]}x + {model.intercept_}")



# Veriyi görselleştirme
plt.scatter(X, y)
plt.plot(X, y_pred, color='red')
plt.xlabel("Metrekare")
plt.ylabel("Fiyat")
plt.title("Metrekareye Göre Fiyat Tahmini")
plt.show()

# Dolar Tahmin Lineer Regressyon

import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
from sklearn.preprocessing import PolynomialFeatures
import os



file_path = r"/tmp/2016dolaralis.csv"
if os.path.exists(file_path):
    print("Dosya bulundu.")
else:
    print("Dosya bulunamadı.")

veri = pd.read_csv(file_path)

print(veri)

x = veri ["Gun"]
y = veri ["Fiyat"]

#x = x.values.reshape(251,1)
#y = y.values.reshape ( 251,1)

# Veriyi şekillendir
x = x.values.reshape(-1, 1)  # Otomatik boyutlandırma
y = y.values.reshape(-1, 1)


# tüm noktaların gösterimi
plt.scatter(x,y)

#Lineer Regressyon ve Polinom Regressyon

# tüm noktaların gösterimi
plt.scatter(x,y)


#Lineer Regressyon
tahminLineer = LinearRegression()
tahminLineer.fit(x,y)
tahminLineer.predict(x)

plt.plot(x, tahminLineer.predict(x) , c="red")


# polinom Regressyon
tahminpolinom = PolynomialFeatures(degree=2)
Xyeni = tahminpolinom.fit_transform(x)

polinommodel = LinearRegression()
polinommodel.fit(Xyeni, y)
polinommodel.predict(Xyeni)
plt.plot (x ,   polinommodel.predict(Xyeni) , c="orange")

plt.show()

# Kareler farkı yöntemini kullanarak hata fonksiyonlarını bulma

from sklearn.preprocessing import PolynomialFeatures
from sklearn.linear_model import LinearRegression
import numpy as np

# x ve y burada tanımlanmış olmalı, örneğin:
# x = np.array([...])
# y = np.array([...])

hatakaresipolinom = 0

for a in range(150):
    tahminpolinom = PolynomialFeatures(degree=a + 1)
    Xyeni = tahminpolinom.fit_transform(x)

    polinommodel = LinearRegression()
    polinommodel.fit(Xyeni, y)
    y_pred = polinommodel.predict(Xyeni)  # Tahminleri bir değişkene alıyoruz

    for i in range(len(Xyeni)):
        hatakaresipolinom += (float(y[i]) - float(y_pred[i])) ** 2  # Skalar değer için `y_pred[i]`

    print(f"{a + 1} inci dereceden fonksiyonda hata: {hatakaresipolinom:.3f}")

    hatakaresipolinom = 0

import os

file_path2 = r"/tmp/breast-cancer-wisconsin.data"
if os.path.exists(file_path2):
    print("Dosya bulundu.")
else:
    print("Dosya bulunamadı.")

#  k-nearest neighbors (KNN) algorithm kullanarak kanser datasetinden hasta ve sağlıklı insanları predict etme
# 2 -> sağlıklı, 4-> kanserli

import numpy as np
from sklearn.impute import SimpleImputer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
import pandas as pd



# Veriyi yükle
veri = pd.read_csv(file_path2)

# '?' karakterlerini -99999 ile değiştir
veri.replace('?', -99999, inplace=True)

# 'id' sütununu düşür
veri.drop(['id'], axis=1, inplace=True)

# Hedef ve özellikleri ayır
y = veri['benormal']
x = veri.drop(['benormal'], axis=1)

# Eksik değerleri doldurmak için SimpleImputer kullan
imp = SimpleImputer(missing_values=-99999, strategy="mean")
x = imp.fit_transform(x)

# K-Nearest Neighbors modelini oluştur ve eğit
tahmin = KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='euclidean')
tahmin.fit(x, y)

# Eğitim verisi üzerindeki tahminler ve doğruluk
ytahmin = tahmin.predict(x)
basari = accuracy_score(y, ytahmin)

print("Yüzde", basari * 100, " oranında başarı sağlandı.")

# Yeni bir örnek üzerinde tahmin yap
# Not: Burada girdi olarak verilen liste, modelin beklediği özellik sayısına uymalıdır.
try:
    print(tahmin.predict([[1, 2, 2, 2, 3, 2, 1, 2, 3]]))
except ValueError as e:
    print("Hata:", e)



# Farklı k-komşuluk değerleri seçildiğinde başarı oranının hesaplanması
for z in range(25):
    z = 2*z+1
    print("En yakın",z,"komşu kullandığımızda tutarlılık oranımız")
    tahmin = KNeighborsClassifier(n_neighbors=z , weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='euclidean')
    tahmin.fit(x,y)
    ytahmin = tahmin.predict(x)

    basari = accuracy_score(y, ytahmin, normalize=True, sample_weight=None)
    print(basari)

# K-fold cross validation yöntemi kullanarak kanser tespitinin yapılması
# test ve train olarak 2 sınıfa ayrılıyor öncelikle

import numpy as np
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score
import pandas as pd
from sklearn.impute import SimpleImputer
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler



imp= SimpleImputer(missing_values=-99999, strategy="mean")

X_train, X_test, y_train, y_test= train_test_split(x,y, test_size=0.2)
x= imp.fit_transform(x)

scaler=StandardScaler()
scaler.fit(X_train)

X_train=scaler.transform(X_train)
X_test=scaler.transform(X_test)

"""for z in range(25):
    z = 2*z+1
    print("En yakın",z,"komşu kullandığımızda tutarlılık oranımız")
    tahmin = KNeighborsClassifier(n_neighbors=z, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='euclidean', metric_params=None, n_jobs=1)
    tahmin.fit(x,y)
    ytahmin = tahmin.predict(x)

    basari = accuracy_score(y, ytahmin, normalize=True, sample_weight=None)
    print(basari)"""

tahmin= KNeighborsClassifier(n_neighbors=3, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='euclidean', metric_params=None, n_jobs=1)
tahmin.fit(X_train , y_train)
ytahmin=tahmin.predict(x)
basari= tahmin.score(X_test, y_test)
print("Yüzde",basari*100," oranında:" )
a= np.array([1,2,2,2,3,2,1,2,3]).reshape(1,-1)
print(tahmin.predict(a))

# Makine Öğrenmesi 20 - Decision Tree Coding

from sklearn.datasets import load_iris
from sklearn import tree
import pydotplus
from sklearn import datasets
from sklearn import metrics
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import cross_val_score
import sklearn

iris = datasets.load_iris()

model = DecisionTreeClassifier()
model.fit(iris.data, iris.target)

# Tek bir örnek için tahmin yap
sample = [6.7, 3.3, 5.7, 2.5]
prediction = model.predict([sample])  # Listeyi iki boyutlu hale getir
print("Tahmin edilen sınıf:", prediction)
print("Tahmin edilen sınıf ismi :", iris.target_names [prediction] )

# print(iris.target_names)

# ders 21 . yapay sinir ağlarını öğrenelim
# sadece bir nörona sahip bir sinir ağı oluşturma
import numpy
from numpy import exp, array, random,dot,mean,abs

girdi = array  ( [ [0,0,1] , [1,1,1] ,  [1,0,1]  ])

gerceksonuc = array  ( [ [0,1,1] ]).T

agirlik = array ( [ [1.0, 1.0, 1.0] ] ).T

for tekrar in range(100) :
  hucredegeri = dot (girdi , agirlik)
  #print(hucredegeri)

  tahmin = 1/ (1 + exp (-hucredegeri) )
  #print(tahmin)

  agirlik =  agirlik + dot (girdi.T, ( ( gerceksonuc -tahmin)* tahmin *(1-tahmin) )   )

 # print ( str (numpy.mean (numpy.abs(gerceksonuc - tahmin ))))


  # Tahmin yaptırma

print( 1 / (1 + exp (- (dot (array( [1,0,0]), agirlik )))) )

# Filepath kontrol edilmesi
import os

file_path5 = r"/tmp/dad.png"
if os.path.exists(file_path5):
    print("Dosya bulundu.")
else:
    print("Dosya bulunamadı.")

# Tensorflow uygulaması
# El yazısı rakamı tanıma



from tensorflow.examples.tutorials.mnist import input_data
mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
import scipy.ndimage
import tensorflow as tf
import numpy as np

x = tf.placeholder(tf.float32, [None, 784])

W = tf.Variable(tf.zeros([784, 10]))

b = tf.Variable(tf.zeros([10]))

y = tf.nn.softmax(tf.matmul(x, W) + b)

y_ = tf.placeholder(tf.float32, [None, 10])

cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y), reduction_indices=[1]))

train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)

sess = tf.InteractiveSession()

tf.global_variables_initializer().run()

for _ in range(1000):
  batch_xs, batch_ys = mnist.train.next_batch(100)
  sess.run(train_step, feed_dict={x: batch_xs, y_: batch_ys})

correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))

accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))

print(sess.run(accuracy, feed_dict={x: mnist.test.images, y_: mnist.test.labels}))

cizim = np.vectorize(lambda x: 255 - x)(np.ndarray.flatten(scipy.ndimage.imread(file_path5, flatten=True)))

sonuc = sess.run(tf.argmax(y, 1), feed_dict={x: [cizim]})

print(sonuc)

# Tensorflow 1- Keras Ve Mnist ile kavramları öğrenme, El yazısı Tanıma

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.utils import to_categorical

# MNIST veri setini yükleme
(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()

# Veriyi normalize etme ve yeniden şekillendirme
X_train = X_train.reshape(-1, 28, 28, 1).astype("float32") / 255.0
X_test = X_test.reshape(-1, 28, 28, 1).astype("float32") / 255.0

# Etiketleri one-hot encoding ile dönüştürme
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)


print(type(X_train), X_train.dtype)  # np.ndarray ve float32 olmalı
print(type(y_train), y_train.dtype)  # np.ndarray ve float32 veya int32 olmalı

X_train = X_train.astype('float32')
y_train = y_train.astype('float32')
X_test = X_test.astype('float32')
y_test = y_test.astype('float32')

import tensorflow as tf
tf.config.run_functions_eagerly(True)
print(tf.__version__)

import tensorflow as tf
from tensorflow.keras import layers, models
from tensorflow.keras.utils import to_categorical

# MNIST veri setini yükleme
(X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()

# Veriyi normalize etme ve yeniden şekillendirme
X_train = X_train.reshape(-1, 28, 28, 1).astype("float32") / 255.0
X_test = X_test.reshape(-1, 28, 28, 1).astype("float32") / 255.0

# Etiketleri one-hot encoding ile dönüştürme
y_train = to_categorical(y_train, 10)
y_test = to_categorical(y_test, 10)

# Model oluşturma
model = models.Sequential([
    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    layers.MaxPooling2D((2, 2)),
    layers.Conv2D(64, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Flatten(),
    layers.Dense(128, activation='relu'),
    layers.Dense(10, activation='softmax')
])

# Modeli derleme
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# Modeli eğitme
model.fit(X_train, y_train, epochs=5, batch_size=32, validation_split=0.1)

# Modeli test etme
test_loss, test_acc = model.evaluate(X_test, y_test)
print(f"Test Accuracy: {test_acc:.4f}")

# Modeli kaydetme (isteğe bağlı)
model.save("mnist_digit_recognition_model.h5")

import shutil
from google.colab import drive

drive.mount("/content/gdrive")

import os

file_path = r"/content/gdrive/MyDrive/dad.png"
if os.path.exists(file_path):
    print("Dosya bulundu.")
else:
    print("Dosya bulunamadı.")

import tensorflow as tf
import numpy as np
from PIL import Image

# Eğitilmiş modeli yükleme
model = tf.keras.models.load_model("mnist_digit_recognition_model.h5")

# Tahmin için bir görüntüyü işleme
def preprocess_image(image_path):
    img = Image.open(image_path).convert('L')  # Görüntüyü gri tonlamaya çevir
    img = img.resize((28, 28))  # MNIST boyutuna yeniden boyutlandır
    img_array = np.array(img)  # Görüntüyü NumPy dizisine çevir
    img_array = 255 - img_array  # Siyah beyazı tersine çevir (el yazısı MNIST ile uyumlu)
    img_array = img_array / 255.0  # Normalize et
    img_array = img_array.reshape(1, 28, 28, 1)  # Modelin giriş boyutuna göre yeniden şekillendir
    return img_array

# Görüntüyü tahmin etme
image_path = file_path
processed_image = preprocess_image(image_path)
prediction = model.predict(processed_image)
predicted_digit = np.argmax(prediction)  # En yüksek olasılık değerine sahip sınıfı al

# Sonucu yazdırma
print(f"Tahmin edilen rakam: {predicted_digit}")